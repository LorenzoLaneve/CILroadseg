{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"unet.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"}},"cells":[{"cell_type":"markdown","metadata":{"id":"tMc3iZD22xKu","colab_type":"text"},"source":["## U-Net model\n","\n","This notebook considers training and visualization of the U-Net model."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1uw9GDoh-iLo","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1595542652866,"user_tz":-120,"elapsed":909,"user":{"displayName":"osnapitzkindle","photoUrl":"https://lh5.googleusercontent.com/-WviiFWOc9yU/AAAAAAAAAAI/AAAAAAAAABg/5UfVNmCmUPs/s64/photo.jpg","userId":"17296883532666308644"}},"outputId":"403dc7ac-4f68-4fec-c21b-5c6675a5de72"},"source":["try: # Google Colab integration\n","  from google.colab import drive\n","\n","  print('Colab environment detected. Mounting drive...')\n","  drive.mount('/content/drive')\n","\n","  print('Mounted. Switching to directory... ', end = '')\n","  %cd /content/drive/'My Drive'/CILroadseg\n","  print('done.')\n","except:\n","  print('Colab environment not found. Working on ordinary directory.')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Colab environment detected. Mounting drive...\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Mounted. Switching to directory... /content/drive/My Drive/CILroadseg\n","done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0DFhJYFbzlSH","colab":{}},"source":["import numpy as np\n","np.random.seed(18)\n","\n","import tensorflow as tf\n","tf.random.set_seed(33)\n","\n","import sys\n","import os\n","import matplotlib.image as mpimg\n","\n","from util.submit import *      # util/submit.py contains the functions used to generate the CSV file for Kaggle Competition\n","from util.visualize import *   # util/visualize.py provides functions for image visualization\n","from util.notebooks import *   # util/notebooks.py contains various util functions used in notebooks"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"g3z8-TugzlSK"},"source":["## Loading Training Data\n","\n","`nb_load_data` is an helper function provided in `util/notebooks.py`"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"R3FcceoMzlSL","colab":{"base_uri":"https://localhost:8080/","height":187},"executionInfo":{"status":"ok","timestamp":1595542659866,"user_tz":-120,"elapsed":7851,"user":{"displayName":"osnapitzkindle","photoUrl":"https://lh5.googleusercontent.com/-WviiFWOc9yU/AAAAAAAAAAI/AAAAAAAAABg/5UfVNmCmUPs/s64/photo.jpg","userId":"17296883532666308644"}},"outputId":"bc487d7b-df4f-463e-c7ec-c562f58b2fba"},"source":["train_dir = \"training/images/\"\n","gt_dir = \"training/groundtruth/\"\n","test_dir = \"test/images/\"\n","\n","X, Y, X_test = nb_load_data(train_dir, gt_dir, test_dir)\n","\n","Y = (Y >= 0.25) * 1"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Loading training input...\n","Progress: done (100 images).\n","Loading training groundtruth...\n","Progress: done (100 images).\n","Loading test input...\n","Progress: done (94 images).\n","\n","       Training data shape: (100, 400, 400, 3)\n","Training groundtruth shape: (100, 400, 400)\n","           Test data shape: (94, 608, 608, 3)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"NelvP11czlSO"},"source":["## Working with the Model\n","\n","The `UNetModel` class is a subclass of `ModelBase`.\n","This base class can be found in `util/model_base.py` and provides a common interface to all the models we created.\n","\n","In particular:\n","- `initialize()` resets the state of the object and should be called before the training starts\n","- `train(Y, X)` takes the training data `X` and its groundtruth `Y` to train the model\n","- `classify(X)` returns the predictions for `X`\n","- `load(filename)` and `save(filename)` load and save weights of the Neural Network from file.\n","\n","---\n","\n","The UNet masks returned by `UNetModel` still have predictions in [0, 1], thus we use the `Discretizer` decorator to round them."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"J1U5t-IEzlSP","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595542659869,"user_tz":-120,"elapsed":7840,"user":{"displayName":"osnapitzkindle","photoUrl":"https://lh5.googleusercontent.com/-WviiFWOc9yU/AAAAAAAAAAI/AAAAAAAAABg/5UfVNmCmUPs/s64/photo.jpg","userId":"17296883532666308644"}},"outputId":"8a416e7a-58e6-4396-cd5f-bb76d3a5363e"},"source":["from tensorflow import keras\n","\n","from discretize import *\n","from rotate_mean import *\n","from unet import *"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qXC8Ba620oIj","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1595548909037,"user_tz":-120,"elapsed":6256987,"user":{"displayName":"osnapitzkindle","photoUrl":"https://lh5.googleusercontent.com/-WviiFWOc9yU/AAAAAAAAAAI/AAAAAAAAABg/5UfVNmCmUPs/s64/photo.jpg","userId":"17296883532666308644"}},"outputId":"676cda5e-64c2-4d34-cdc7-58682dc84ab5"},"source":["model = UNetModel()\n","# For the U-Net model, data augmentation and\n","# recomposition are done in the UNetModel class.\n","\n","model_dsc = Discretizer(model, threshold=0.5)\n","# We round the labels to 0 or 1, using 0.5 as threshold.\n","\n","model_rnm = Discretizer(RotAndMean(model), threshold=0.5)\n","# Segments the image for every possible rotation/flip\n","# combinations and computes the pixelwise mean of predictions\n","# then the mean is rounded to the nearest integer as in model_dsc.\n","\n","\n","DO_TRAINING = False\n","if DO_TRAINING:\n","  model.initialize()\n","  model.train(Y, X)\n","\n","  model.save(\"saves/final/unet.h5\")\n","else:\n","  model.initialize()\n","  model.load(\"saves/final/unet-rotation+color.h5\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["seed: 4\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 304, 304, 3)  0                                            \n","__________________________________________________________________________________________________\n","conv2d_1 (Conv2D)               (None, 304, 304, 32) 2432        input_1[0][0]                    \n","__________________________________________________________________________________________________\n","re_lu_1 (ReLU)                  (None, 304, 304, 32) 0           conv2d_1[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_2 (Conv2D)               (None, 304, 304, 32) 25632       re_lu_1[0][0]                    \n","__________________________________________________________________________________________________\n","re_lu_2 (ReLU)                  (None, 304, 304, 32) 0           conv2d_2[0][0]                   \n","__________________________________________________________________________________________________\n","max_pooling2d_1 (MaxPooling2D)  (None, 152, 152, 32) 0           re_lu_2[0][0]                    \n","__________________________________________________________________________________________________\n","conv2d_3 (Conv2D)               (None, 152, 152, 64) 18496       max_pooling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","re_lu_3 (ReLU)                  (None, 152, 152, 64) 0           conv2d_3[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_4 (Conv2D)               (None, 152, 152, 64) 36928       re_lu_3[0][0]                    \n","__________________________________________________________________________________________________\n","re_lu_4 (ReLU)                  (None, 152, 152, 64) 0           conv2d_4[0][0]                   \n","__________________________________________________________________________________________________\n","max_pooling2d_2 (MaxPooling2D)  (None, 76, 76, 64)   0           re_lu_4[0][0]                    \n","__________________________________________________________________________________________________\n","conv2d_5 (Conv2D)               (None, 76, 76, 128)  73856       max_pooling2d_2[0][0]            \n","__________________________________________________________________________________________________\n","re_lu_5 (ReLU)                  (None, 76, 76, 128)  0           conv2d_5[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_6 (Conv2D)               (None, 76, 76, 128)  147584      re_lu_5[0][0]                    \n","__________________________________________________________________________________________________\n","re_lu_6 (ReLU)                  (None, 76, 76, 128)  0           conv2d_6[0][0]                   \n","__________________________________________________________________________________________________\n","max_pooling2d_3 (MaxPooling2D)  (None, 38, 38, 128)  0           re_lu_6[0][0]                    \n","__________________________________________________________________________________________________\n","conv2d_7 (Conv2D)               (None, 38, 38, 256)  295168      max_pooling2d_3[0][0]            \n","__________________________________________________________________________________________________\n","re_lu_7 (ReLU)                  (None, 38, 38, 256)  0           conv2d_7[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 38, 38, 256)  590080      re_lu_7[0][0]                    \n","__________________________________________________________________________________________________\n","re_lu_8 (ReLU)                  (None, 38, 38, 256)  0           conv2d_8[0][0]                   \n","__________________________________________________________________________________________________\n","max_pooling2d_4 (MaxPooling2D)  (None, 19, 19, 256)  0           re_lu_8[0][0]                    \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 19, 19, 512)  1180160     max_pooling2d_4[0][0]            \n","__________________________________________________________________________________________________\n","re_lu_9 (ReLU)                  (None, 19, 19, 512)  0           conv2d_9[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 19, 19, 512)  2359808     re_lu_9[0][0]                    \n","__________________________________________________________________________________________________\n","re_lu_10 (ReLU)                 (None, 19, 19, 512)  0           conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","up_sampling2d_1 (UpSampling2D)  (None, 38, 38, 512)  0           re_lu_10[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 38, 38, 256)  1179904     up_sampling2d_1[0][0]            \n","__________________________________________________________________________________________________\n","re_lu_11 (ReLU)                 (None, 38, 38, 256)  0           conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 38, 38, 512)  0           re_lu_8[0][0]                    \n","                                                                 re_lu_11[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 38, 38, 256)  1179904     concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","re_lu_12 (ReLU)                 (None, 38, 38, 256)  0           conv2d_12[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 38, 38, 256)  590080      re_lu_12[0][0]                   \n","__________________________________________________________________________________________________\n","re_lu_13 (ReLU)                 (None, 38, 38, 256)  0           conv2d_13[0][0]                  \n","__________________________________________________________________________________________________\n","up_sampling2d_2 (UpSampling2D)  (None, 76, 76, 256)  0           re_lu_13[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 76, 76, 128)  295040      up_sampling2d_2[0][0]            \n","__________________________________________________________________________________________________\n","re_lu_14 (ReLU)                 (None, 76, 76, 128)  0           conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 76, 76, 256)  0           re_lu_6[0][0]                    \n","                                                                 re_lu_14[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 76, 76, 128)  295040      concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","re_lu_15 (ReLU)                 (None, 76, 76, 128)  0           conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_16 (Conv2D)              (None, 76, 76, 128)  147584      re_lu_15[0][0]                   \n","__________________________________________________________________________________________________\n","re_lu_16 (ReLU)                 (None, 76, 76, 128)  0           conv2d_16[0][0]                  \n","__________________________________________________________________________________________________\n","up_sampling2d_3 (UpSampling2D)  (None, 152, 152, 128 0           re_lu_16[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_17 (Conv2D)              (None, 152, 152, 64) 73792       up_sampling2d_3[0][0]            \n","__________________________________________________________________________________________________\n","re_lu_17 (ReLU)                 (None, 152, 152, 64) 0           conv2d_17[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_3 (Concatenate)     (None, 152, 152, 128 0           re_lu_4[0][0]                    \n","                                                                 re_lu_17[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_18 (Conv2D)              (None, 152, 152, 64) 73792       concatenate_3[0][0]              \n","__________________________________________________________________________________________________\n","re_lu_18 (ReLU)                 (None, 152, 152, 64) 0           conv2d_18[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_19 (Conv2D)              (None, 152, 152, 64) 36928       re_lu_18[0][0]                   \n","__________________________________________________________________________________________________\n","re_lu_19 (ReLU)                 (None, 152, 152, 64) 0           conv2d_19[0][0]                  \n","__________________________________________________________________________________________________\n","up_sampling2d_4 (UpSampling2D)  (None, 304, 304, 64) 0           re_lu_19[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_20 (Conv2D)              (None, 304, 304, 32) 18464       up_sampling2d_4[0][0]            \n","__________________________________________________________________________________________________\n","re_lu_20 (ReLU)                 (None, 304, 304, 32) 0           conv2d_20[0][0]                  \n","__________________________________________________________________________________________________\n","concatenate_4 (Concatenate)     (None, 304, 304, 64) 0           re_lu_2[0][0]                    \n","                                                                 re_lu_20[0][0]                   \n","__________________________________________________________________________________________________\n","conv2d_21 (Conv2D)              (None, 304, 304, 32) 18464       concatenate_4[0][0]              \n","__________________________________________________________________________________________________\n","re_lu_21 (ReLU)                 (None, 304, 304, 32) 0           conv2d_21[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_22 (Conv2D)              (None, 304, 304, 32) 9248        re_lu_21[0][0]                   \n","__________________________________________________________________________________________________\n","re_lu_22 (ReLU)                 (None, 304, 304, 32) 0           conv2d_22[0][0]                  \n","__________________________________________________________________________________________________\n","conv2d_23 (Conv2D)              (None, 304, 304, 1)  33          re_lu_22[0][0]                   \n","==================================================================================================\n","Total params: 8,648,417\n","Trainable params: 8,648,417\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Epoch 1/50\n"," - 149s - loss: 0.4313 - accuracy: 0.8094\n","Epoch 2/50\n"," - 148s - loss: 0.2717 - accuracy: 0.8801\n","Epoch 3/50\n"," - 150s - loss: 0.2337 - accuracy: 0.8997\n","Epoch 4/50\n"," - 161s - loss: 0.2119 - accuracy: 0.9091\n","Epoch 5/50\n"," - 165s - loss: 0.1995 - accuracy: 0.9137\n","Epoch 6/50\n"," - 156s - loss: 0.1886 - accuracy: 0.9192\n","Epoch 7/50\n"," - 158s - loss: 0.1751 - accuracy: 0.9247\n","Epoch 8/50\n"," - 157s - loss: 0.1789 - accuracy: 0.9228\n","Epoch 9/50\n"," - 157s - loss: 0.1670 - accuracy: 0.9278\n","Epoch 10/50\n"," - 159s - loss: 0.1609 - accuracy: 0.9305\n","Epoch 11/50\n"," - 158s - loss: 0.1584 - accuracy: 0.9316\n","Epoch 12/50\n"," - 157s - loss: 0.1536 - accuracy: 0.9332\n","Epoch 13/50\n"," - 160s - loss: 0.1552 - accuracy: 0.9336\n","Epoch 14/50\n"," - 160s - loss: 0.1463 - accuracy: 0.9364\n","Epoch 15/50\n"," - 159s - loss: 0.1372 - accuracy: 0.9290\n","Epoch 16/50\n"," - 161s - loss: 0.1294 - accuracy: 0.9298\n","Epoch 17/50\n"," - 160s - loss: 0.1207 - accuracy: 0.9346\n","Epoch 18/50\n"," - 160s - loss: 0.1212 - accuracy: 0.9329\n","Epoch 19/50\n"," - 160s - loss: 0.1205 - accuracy: 0.9347\n","\n","Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","Epoch 20/50\n"," - 160s - loss: 0.1052 - accuracy: 0.9410\n","Epoch 21/50\n"," - 159s - loss: 0.1022 - accuracy: 0.9410\n","Epoch 22/50\n"," - 159s - loss: 0.1005 - accuracy: 0.9430\n","Epoch 23/50\n"," - 164s - loss: 0.0986 - accuracy: 0.9438\n","Epoch 24/50\n"," - 165s - loss: 0.0971 - accuracy: 0.9434\n","Epoch 25/50\n"," - 164s - loss: 0.0934 - accuracy: 0.9460\n","Epoch 26/50\n"," - 162s - loss: 0.0945 - accuracy: 0.9450\n","Epoch 27/50\n"," - 162s - loss: 0.0934 - accuracy: 0.9501\n","Epoch 28/50\n"," - 162s - loss: 0.0918 - accuracy: 0.9511\n","Epoch 29/50\n"," - 163s - loss: 0.0921 - accuracy: 0.9509\n","Epoch 30/50\n"," - 163s - loss: 0.0878 - accuracy: 0.9489\n","Epoch 31/50\n"," - 162s - loss: 0.0891 - accuracy: 0.9471\n","Epoch 32/50\n"," - 162s - loss: 0.0865 - accuracy: 0.9485\n","Epoch 33/50\n"," - 163s - loss: 0.0877 - accuracy: 0.9478\n","\n","Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","Epoch 34/50\n"," - 162s - loss: 0.1177 - accuracy: 0.9391\n","Epoch 35/50\n"," - 164s - loss: 0.1114 - accuracy: 0.9437\n","Epoch 36/50\n"," - 166s - loss: 0.1066 - accuracy: 0.9417\n","Epoch 37/50\n"," - 164s - loss: 0.1075 - accuracy: 0.9420\n","Epoch 38/50\n"," - 164s - loss: 0.0962 - accuracy: 0.9455\n","\n","Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n","Epoch 39/50\n"," - 163s - loss: 0.0897 - accuracy: 0.9447\n","Epoch 00039: early stopping\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"z48sHukBqqHh"},"source":["## Making Predictions with the Model\n","\n","`UNetModel.classify(X)` takes the array of images and directly returns the array of full masks.\n","\n","`Discretizer.classify(X)` rounds the values of the output regardless of its shape."]},{"cell_type":"markdown","metadata":{"id":"M6IRaQ8E8TPB","colab_type":"text"},"source":["The function `nb_predict_masks` is an helper function provided in `util/notebooks.py`, while `masks_to_submission` is a function based on the implementation provided in the Kaggle competition.\n","\n","The following two cells can be skipped if you do not want to generate the `.csv` file."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5C5PHZKP9bKi","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1595548978390,"user_tz":-120,"elapsed":6326293,"user":{"displayName":"osnapitzkindle","photoUrl":"https://lh5.googleusercontent.com/-WviiFWOc9yU/AAAAAAAAAAI/AAAAAAAAABg/5UfVNmCmUPs/s64/photo.jpg","userId":"17296883532666308644"}},"outputId":"53471fbe-e658-4521-fbb5-9b9e69e43404"},"source":["test_masks_dir = \"test/pred/unet/\"\n","test_dir = \"test/images/\"\n","\n","# replace model_rnm with model_dsc if you want to generate\n","# the csv file without rotate and mean.\n","nb_predict_masks(model_rnm, test_dir, test_masks_dir)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Predicting test cases... \n","Progress: done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"eQQ7wKtmGOdM","colab":{}},"source":["image_paths = [test_masks_dir + file for file in os.listdir(test_masks_dir)]\n","masks_to_submission(\"test/unet.csv\", image_paths)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jcmPnqFFs3vb","colab_type":"text"},"source":["This prediction achieved an F1 score of 0.916 in Kaggle's public test set."]},{"cell_type":"markdown","metadata":{"id":"5iiRoNEP7y4n","colab_type":"text"},"source":["# Visualizing predictions\n","\n","The function `view_image_array` is provided in `util/visualize.py`. It uses `matplotlib` to visualize the images and the corresponding predictions."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"MiKljqBGpCkq","colab":{}},"source":["Y_pred     = model.classify(X_test[0:10])\n","Y_pred_dsc = model_dsc.classify(X_test[0:10])\n","Y_pred_rnm = model_rnm.classify(X_test[0:10])\n","\n","view_image_array(X_test[0:10], Y_pred, Y_pred_dsc, Y_pred_rnm)\n","\n","# For each row we have: image, unrounded mask, rounded mask, mask with rotate and mean"],"execution_count":null,"outputs":[]}]}