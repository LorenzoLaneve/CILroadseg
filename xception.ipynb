{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"xception.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.2"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"rRa7N3dXJ6Dt"},"source":["## **Per-Patch Classification: Xception based Classifier**\n","This notebook considers training and visualization of the per-patch classifier based on the Xception model.\n","\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1uw9GDoh-iLo","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1595863104166,"user_tz":-120,"elapsed":641,"user":{"displayName":"osnapitzkindle","photoUrl":"https://lh5.googleusercontent.com/-WviiFWOc9yU/AAAAAAAAAAI/AAAAAAAAABg/5UfVNmCmUPs/s64/photo.jpg","userId":"17296883532666308644"}},"outputId":"3bd83099-2256-4dd1-bd73-f8d11b22bcc1"},"source":["    try: # Google Colab integration\n","        from google.colab import drive\n","\n","        print('Colab environment detected. Mounting drive...')\n","        drive.mount('/content/drive')\n","\n","        print('Mounted. Switching to directory... ', end = '')\n","        %cd /content/drive/'My Drive'/CILroadseg\n","        print('done.')\n","    except:\n","        print('Colab environment not found. Working on ordinary directory.')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Colab environment detected. Mounting drive...\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Mounted. Switching to directory... /content/drive/My Drive/CILroadseg\n","done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0DFhJYFbzlSH","colab":{},"executionInfo":{"status":"ok","timestamp":1595863105800,"user_tz":-120,"elapsed":2225,"user":{"displayName":"osnapitzkindle","photoUrl":"https://lh5.googleusercontent.com/-WviiFWOc9yU/AAAAAAAAAAI/AAAAAAAAABg/5UfVNmCmUPs/s64/photo.jpg","userId":"17296883532666308644"}}},"source":["import numpy as np\n","np.random.seed(1)\n","\n","import tensorflow as tf\n","\n","import sys\n","import os\n","import matplotlib.image as mpimg\n","\n","from util.submit import *      # util/submit.py contains the functions used to generate the CSV file for Kaggle Competition\n","from util.visualize import *   # util/visualize.py provides functions for image visualization\n","from util.notebooks import *   # util/notebooks.py contains various util functions used in notebooks"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"g3z8-TugzlSK"},"source":["# **Loading Training Data**\n","`nb_load_data` is an helper function provided in `util/notebooks.py`"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"R3FcceoMzlSL","colab":{"base_uri":"https://localhost:8080/","height":187},"executionInfo":{"status":"ok","timestamp":1595863111282,"user_tz":-120,"elapsed":7679,"user":{"displayName":"osnapitzkindle","photoUrl":"https://lh5.googleusercontent.com/-WviiFWOc9yU/AAAAAAAAAAI/AAAAAAAAABg/5UfVNmCmUPs/s64/photo.jpg","userId":"17296883532666308644"}},"outputId":"5cc15820-16ff-4701-b74e-ee19670b3ff1"},"source":["train_dir = \"training/images_additionaldata/\"\n","gt_dir = \"training/groundtruth_additionaldata/\"\n","test_dir = \"test/images/\"\n","# here we use additional training data as mentioned in the report.\n","# use \"training/images/\" and \"training/groundtruth\" to\n","# reproduce the baseline Xception\n","\n","X, Y, X_test = nb_load_data(train_dir, gt_dir, test_dir)\n","Y = (Y >= 0.25) * 1"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Loading training input...\n","Progress: done (148 images).\n","Loading training groundtruth...\n","Progress: done (148 images).\n","Loading test input...\n","Progress: done (94 images).\n","\n","       Training data shape: (148, 400, 400, 3)\n","Training groundtruth shape: (148, 400, 400)\n","           Test data shape: (94, 608, 608, 3)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"NelvP11czlSO"},"source":["# **Working with the Model**\n","The `XceptionModel` and `Decomposer` class are subclasses of `ModelBase`. This base class can be found in `util/model_base.py` and provides a common interface to all the models we created.\n","\n","In particular:\n","\n","`initialize()` resets the state of the object and should be called before the \n","\n","*   `initialize()` resets the state of the object and should be called before the training starts\n","*   `train(Y, X)` takes the training data X and its groundtruth Y to train the model\n","*   `classify(X)` returns the predictions for X\n","*   `load(filename)` and `save(filename)` load and save weights of the Neural Network from file.\n","\n","The `Decomposer` class is a decorator which performs bootstrapping and data augmentation for all the per-patch classifiers (in this case `XceptionModel`).\n","\n","The `Discretizer` decorator transforms the output of the inner model from [0, 1] to {0, 1} rounding to either 0 or 1 based on the given threshold.\n","\n","One can allocate a model like below."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"J1U5t-IEzlSP","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595863111475,"user_tz":-120,"elapsed":7851,"user":{"displayName":"osnapitzkindle","photoUrl":"https://lh5.googleusercontent.com/-WviiFWOc9yU/AAAAAAAAAAI/AAAAAAAAABg/5UfVNmCmUPs/s64/photo.jpg","userId":"17296883532666308644"}},"outputId":"82e91323-fe27-447d-a44c-5ca07dc7edfb"},"source":["from decomposer import *\n","from discretize import * \n","from xception import *\n","from rotate_mean import * "],"execution_count":4,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"8VYuQhskzlSS","colab":{"base_uri":"https://localhost:8080/","height":357},"executionInfo":{"status":"ok","timestamp":1595863118238,"user_tz":-120,"elapsed":14568,"user":{"displayName":"osnapitzkindle","photoUrl":"https://lh5.googleusercontent.com/-WviiFWOc9yU/AAAAAAAAAAI/AAAAAAAAABg/5UfVNmCmUPs/s64/photo.jpg","userId":"17296883532666308644"}},"outputId":"fef719c9-853b-4460-ea33-f6d0b1f42880"},"source":["model = XceptionModel()\n","# This is the core model. It takes windows and returns labels for patches.\n","\n","model = RotAndMean(XceptionModel())\n","# This line can be commented out in order to use Xception without\n","# Rotate and Mean ensemble \n","\n","model = Decomposer(model, window_size=200)\n","# The decomposer decorator takes full images. During training phase\n","# it does data augmentation and window sampling, while during\n","# prediction it divides the images in windows and passes them\n","# to the inner model.\n","\n","model = Discretizer(model, threshold=0.5)\n","\n","DO_TRAINING = False\n","if DO_TRAINING:\n","  model.initialize()\n","  model.train(Y, X)\n","\n","  model.save(\"saves/final/xception.h5\")\n","else:\n","  model.initialize()\n","  model.load(\"saves/final/xception-additionaldata.h5\")"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","model_1 (Model)              (None, 100352)            20861480  \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 64)                6422592   \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 64)                0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 64)                4160      \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 64)                0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 1)                 65        \n","=================================================================\n","Total params: 27,288,297\n","Trainable params: 27,233,769\n","Non-trainable params: 54,528\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"wu592JXiLwd3"},"source":["# **Making Predictions with the Model**\n","`Decomposer.classify(X)` decomposes the images of X into windows and then calls `XceptionModel.classify(X)` to do the patchwise classification, but it does not recompose the images. This is true for all the patchwise classifiers we created, because having patchwise predictions can be useful in certain cases.\n","\n","If you want the model to return full masks, you need to wrap it into a `Recomposer` decorator, as below. The implementation of this decorator class can be found in `recomposer.py.`"]},{"cell_type":"code","metadata":{"id":"67Ht0d5fbjv0","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595863118241,"user_tz":-120,"elapsed":14508,"user":{"displayName":"osnapitzkindle","photoUrl":"https://lh5.googleusercontent.com/-WviiFWOc9yU/AAAAAAAAAAI/AAAAAAAAABg/5UfVNmCmUPs/s64/photo.jpg","userId":"17296883532666308644"}}},"source":["from recomposer import *\n","model = Recomposer(model)"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GbAjLVArb6_v","colab_type":"text"},"source":["The function `nb_predict_masks` is an helper function provided in `util/notebooks.py`, while `masks_to_submission` is a function based on the implementation provided in the Kaggle competition.\n","\n","The following two cells can be skipped if you do not want to generate the `.csv` file.\n","\n","**Warning:** Mask prediction for Xception may need more than 12 GB of RAM."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5C5PHZKP9bKi","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"92ba02cd-9810-4200-9dd5-a7b311159d0c"},"source":["test_masks_dir = \"test/pred/\"\n","test_dir = \"test/images/\"\n","\n","nb_predict_masks(model, test_dir, test_masks_dir)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Predicting test cases... \n","Progress: 54%"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"eQQ7wKtmGOdM","colab":{}},"source":["image_paths = [test_masks_dir + file for file in os.listdir(test_masks_dir)]\n","\n","masks_to_submission(\"test/csv/xception.csv\", image_paths)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"AtS8dC0RMWn4"},"source":["# **Visualizing predictions**\n","The function view_image_array is provided in `util/visualize.py`. It uses `matplotlib` to visualize the images and the corresponding predictions."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1K7lCFlZfXXe","colab":{}},"source":["Xt = X_test[0:1]\n","\n","Y_pred = model.classify(Xt)\n","\n","view_image_array(Xt, Y_pred)"],"execution_count":null,"outputs":[]}]}