{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"xception.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.7"}},"cells":[{"cell_type":"markdown","metadata":{"id":"tMc3iZD22xKu","colab_type":"text"},"source":["## Per-Patch Classification: Xception based Classifier\n","\n","This notebook considers training and visualization of the per-patch classifier based on the Xception model."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1uw9GDoh-iLo","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1595171963606,"user_tz":-120,"elapsed":689,"user":{"displayName":"osnapitzkindle","photoUrl":"https://lh5.googleusercontent.com/-WviiFWOc9yU/AAAAAAAAAAI/AAAAAAAAABg/5UfVNmCmUPs/s64/photo.jpg","userId":"17296883532666308644"}},"outputId":"577d9d59-6100-4914-e256-645afdfb0c0b"},"source":["try: # Google Colab integration\n","  from google.colab import drive\n","\n","  print('Colab environment detected. Mounting drive...')\n","  drive.mount('/content/drive')\n","\n","  print('Mounted. Switching to directory... ', end = '')\n","  %cd /content/drive/'My Drive'/CILroadseg\n","  print('done.')\n","except:\n","  print('Colab environment not found. Working on ordinary directory.')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Colab environment detected. Mounting drive...\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Mounted. Switching to directory... /content/drive/My Drive/CILroadseg\n","done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0DFhJYFbzlSH","colab":{}},"source":["import numpy as np\n","np.random.seed(18)\n","\n","import tensorflow as tf\n","tf.random.set_seed(33)\n","\n","import sys\n","import os\n","import matplotlib.image as mpimg\n","\n","from util.submit import *      # util/submit.py contains the functions used to generate the CSV file for Kaggle Competition\n","from util.visualize import *   # util/visualize.py provides functions for image visualization\n","from util.notebooks import *   # util/notebooks.py contains various util functions used in notebooks"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"g3z8-TugzlSK"},"source":["## Loading Training Data\n","\n","`nb_load_data` is an helper function provided in `util/notebooks.py`"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"R3FcceoMzlSL","colab":{"base_uri":"https://localhost:8080/","height":187},"executionInfo":{"status":"ok","timestamp":1595171970490,"user_tz":-120,"elapsed":7524,"user":{"displayName":"osnapitzkindle","photoUrl":"https://lh5.googleusercontent.com/-WviiFWOc9yU/AAAAAAAAAAI/AAAAAAAAABg/5UfVNmCmUPs/s64/photo.jpg","userId":"17296883532666308644"}},"outputId":"424a7795-26a3-4187-d4be-25efaaf4e1ec"},"source":["train_dir = \"training/images/\"\n","gt_dir = \"training/groundtruth/\"\n","test_dir = \"test/images/\"\n","\n","X, Y, X_test = nb_load_data(train_dir, gt_dir, test_dir)\n","\n","Y = (Y >= 0.25) * 1"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Loading training input...\n","Progress: done (100 images).\n","Loading training groundtruth...\n","Progress: done (100 images).\n","Loading test input...\n","Progress: done (94 images).\n","\n","       Training data shape: (100, 400, 400, 3)\n","Training groundtruth shape: (100, 400, 400)\n","           Test data shape: (94, 608, 608, 3)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"NelvP11czlSO"},"source":["## Working with the Model\n","\n","The `XceptionModel` and `Decomposer` class is a subclass of `ModelBase`.\n","This base class can be found in `util/model_base.py` and provides a common interface to all the models we created.\n","\n","In particular:\n","- `initialize()` resets the state of the object and should be called before the training starts\n","- `train(Y, X)` takes the training data `X` and its groundtruth `Y` to train the model\n","- `classify(X)` returns the predictions for `X`\n","- `load(filename)` and `save(filename)` load and save weights of the Neural Network from file.\n","\n","---\n","\n","The `Decomposer` class is a decorator which performs bootstrapping and data augmentation for all the per-patch classifiers (in this case `XceptionModel`).\n","\n","The `Discretizer` decorator transforms the output of the inner model from [0, 1] to {0, 1} rounding to either 0 or 1 based on the given threshold.\n","\n","One can allocate a model like below."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"J1U5t-IEzlSP","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1595171971115,"user_tz":-120,"elapsed":8119,"user":{"displayName":"osnapitzkindle","photoUrl":"https://lh5.googleusercontent.com/-WviiFWOc9yU/AAAAAAAAAAI/AAAAAAAAABg/5UfVNmCmUPs/s64/photo.jpg","userId":"17296883532666308644"}},"outputId":"28343f67-f252-4f2c-e95c-a757dc17d7aa"},"source":["from tensorflow import keras\n","\n","from decomposer import *\n","from discretize import *\n","from xception import *"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qXC8Ba620oIj","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1595173120091,"user_tz":-120,"elapsed":1157065,"user":{"displayName":"osnapitzkindle","photoUrl":"https://lh5.googleusercontent.com/-WviiFWOc9yU/AAAAAAAAAAI/AAAAAAAAABg/5UfVNmCmUPs/s64/photo.jpg","userId":"17296883532666308644"}},"outputId":"d714fc63-f0a1-4464-abc7-bb41a84a9e84"},"source":["core_model = XceptionModel()\n","# Definition of this class can be found in xception.py\n","\n","model = Decomposer(core_model, window_size=200)\n","# Xception uses a window of size 200\n","\n","model = Discretizer(model, threshold=0.5)\n","\n","\n","DO_TRAINING = True\n","if DO_TRAINING:\n","  model.initialize()\n","  model.train(Y, X)\n","\n","  model.save(\"saves/final/xception.h5\")\n","else:\n","  model.initialize()\n","  model.load(\"saves/final/xception.h5\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_1 (Conv2D)            (None, 12, 12, 32)        2432      \n","_________________________________________________________________\n","re_lu_1 (ReLU)               (None, 12, 12, 32)        0         \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 6, 6, 32)          0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 2, 2, 64)          51264     \n","_________________________________________________________________\n","re_lu_2 (ReLU)               (None, 2, 2, 64)          0         \n","_________________________________________________________________\n","max_pooling2d_2 (MaxPooling2 (None, 1, 1, 64)          0         \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 64)                0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 64)                4160      \n","_________________________________________________________________\n","re_lu_3 (ReLU)               (None, 64)                0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 1)                 65        \n","=================================================================\n","Total params: 57,921\n","Trainable params: 57,921\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","62500/62500 [==============================] - 12s 188us/step - loss: 0.5552 - accuracy: 0.7283\n","Epoch 2/100\n","62500/62500 [==============================] - 11s 184us/step - loss: 0.4949 - accuracy: 0.7463\n","Epoch 3/100\n","62500/62500 [==============================] - 11s 183us/step - loss: 0.4510 - accuracy: 0.7764\n","Epoch 4/100\n","62500/62500 [==============================] - 12s 184us/step - loss: 0.4363 - accuracy: 0.7866\n","Epoch 5/100\n","62500/62500 [==============================] - 12s 184us/step - loss: 0.4154 - accuracy: 0.8010\n","Epoch 6/100\n","62500/62500 [==============================] - 11s 184us/step - loss: 0.4059 - accuracy: 0.8051\n","Epoch 7/100\n","62500/62500 [==============================] - 11s 182us/step - loss: 0.3945 - accuracy: 0.8137\n","Epoch 8/100\n","62500/62500 [==============================] - 11s 183us/step - loss: 0.3839 - accuracy: 0.8195\n","Epoch 9/100\n","62500/62500 [==============================] - 11s 183us/step - loss: 0.3745 - accuracy: 0.8234\n","Epoch 10/100\n","62500/62500 [==============================] - 11s 182us/step - loss: 0.3698 - accuracy: 0.8257\n","Epoch 11/100\n","62500/62500 [==============================] - 11s 182us/step - loss: 0.3603 - accuracy: 0.8312\n","Epoch 12/100\n","62500/62500 [==============================] - 11s 182us/step - loss: 0.3482 - accuracy: 0.8389\n","Epoch 13/100\n","62500/62500 [==============================] - 12s 184us/step - loss: 0.3446 - accuracy: 0.8401\n","Epoch 14/100\n","62500/62500 [==============================] - 11s 183us/step - loss: 0.3349 - accuracy: 0.8456\n","Epoch 15/100\n","62500/62500 [==============================] - 11s 183us/step - loss: 0.3271 - accuracy: 0.8510\n","Epoch 16/100\n","62500/62500 [==============================] - 12s 184us/step - loss: 0.3217 - accuracy: 0.8526\n","Epoch 17/100\n","62500/62500 [==============================] - 12s 185us/step - loss: 0.3143 - accuracy: 0.8567\n","Epoch 18/100\n","62500/62500 [==============================] - 11s 184us/step - loss: 0.3061 - accuracy: 0.8609\n","Epoch 19/100\n","62500/62500 [==============================] - 12s 185us/step - loss: 0.2987 - accuracy: 0.8640\n","Epoch 20/100\n","62500/62500 [==============================] - 12s 184us/step - loss: 0.2950 - accuracy: 0.8660\n","Epoch 21/100\n","62500/62500 [==============================] - 11s 183us/step - loss: 0.2868 - accuracy: 0.8710\n","Epoch 22/100\n","62500/62500 [==============================] - 11s 182us/step - loss: 0.2837 - accuracy: 0.8721\n","Epoch 23/100\n","62500/62500 [==============================] - 11s 183us/step - loss: 0.2755 - accuracy: 0.8760\n","Epoch 24/100\n","62500/62500 [==============================] - 11s 181us/step - loss: 0.2682 - accuracy: 0.8801\n","Epoch 25/100\n","62500/62500 [==============================] - 11s 183us/step - loss: 0.2621 - accuracy: 0.8838\n","Epoch 26/100\n","62500/62500 [==============================] - 11s 182us/step - loss: 0.2611 - accuracy: 0.8832\n","Epoch 27/100\n","62500/62500 [==============================] - 11s 183us/step - loss: 0.2534 - accuracy: 0.8877\n","Epoch 28/100\n","62500/62500 [==============================] - 11s 183us/step - loss: 0.2485 - accuracy: 0.8900\n","Epoch 29/100\n","62500/62500 [==============================] - 11s 182us/step - loss: 0.2442 - accuracy: 0.8927\n","Epoch 30/100\n","62500/62500 [==============================] - 11s 184us/step - loss: 0.2358 - accuracy: 0.8966\n","Epoch 31/100\n","62500/62500 [==============================] - 11s 184us/step - loss: 0.2352 - accuracy: 0.8949\n","Epoch 32/100\n","62500/62500 [==============================] - 11s 183us/step - loss: 0.2294 - accuracy: 0.8992\n","Epoch 33/100\n","62500/62500 [==============================] - 11s 183us/step - loss: 0.2244 - accuracy: 0.9013\n","Epoch 34/100\n","62500/62500 [==============================] - 11s 184us/step - loss: 0.2231 - accuracy: 0.9023\n","Epoch 35/100\n","62500/62500 [==============================] - 11s 182us/step - loss: 0.2154 - accuracy: 0.9059\n","Epoch 36/100\n","62500/62500 [==============================] - 11s 183us/step - loss: 0.2120 - accuracy: 0.9080\n","Epoch 37/100\n","62500/62500 [==============================] - 11s 183us/step - loss: 0.2160 - accuracy: 0.9047\n","Epoch 38/100\n","62500/62500 [==============================] - 11s 183us/step - loss: 0.2069 - accuracy: 0.9103\n","Epoch 39/100\n","62500/62500 [==============================] - 11s 182us/step - loss: 0.2037 - accuracy: 0.9107\n","Epoch 40/100\n","62500/62500 [==============================] - 11s 182us/step - loss: 0.1988 - accuracy: 0.9137\n","Epoch 41/100\n","62500/62500 [==============================] - 11s 183us/step - loss: 0.1943 - accuracy: 0.9158\n","Epoch 42/100\n","62500/62500 [==============================] - 11s 183us/step - loss: 0.1972 - accuracy: 0.9139\n","Epoch 43/100\n","62500/62500 [==============================] - 11s 183us/step - loss: 0.1910 - accuracy: 0.9170\n","Epoch 44/100\n","62500/62500 [==============================] - 12s 186us/step - loss: 0.1842 - accuracy: 0.9201\n","Epoch 45/100\n","62500/62500 [==============================] - 11s 182us/step - loss: 0.1854 - accuracy: 0.9196\n","Epoch 46/100\n","62500/62500 [==============================] - 12s 184us/step - loss: 0.1826 - accuracy: 0.9211\n","Epoch 47/100\n","62500/62500 [==============================] - 11s 184us/step - loss: 0.1792 - accuracy: 0.9229\n","Epoch 48/100\n","62500/62500 [==============================] - 12s 184us/step - loss: 0.1792 - accuracy: 0.9222\n","Epoch 49/100\n","62500/62500 [==============================] - 11s 183us/step - loss: 0.1715 - accuracy: 0.9270\n","Epoch 50/100\n","62500/62500 [==============================] - 11s 183us/step - loss: 0.1713 - accuracy: 0.9257\n","Epoch 51/100\n","62500/62500 [==============================] - 11s 183us/step - loss: 0.1718 - accuracy: 0.9259\n","Epoch 52/100\n","62500/62500 [==============================] - 11s 182us/step - loss: 0.1680 - accuracy: 0.9282\n","Epoch 53/100\n","62500/62500 [==============================] - 11s 183us/step - loss: 0.1638 - accuracy: 0.9295\n","Epoch 54/100\n","62500/62500 [==============================] - 12s 185us/step - loss: 0.1663 - accuracy: 0.9286\n","Epoch 55/100\n","62500/62500 [==============================] - 12s 185us/step - loss: 0.1611 - accuracy: 0.9314\n","Epoch 56/100\n","62500/62500 [==============================] - 12s 185us/step - loss: 0.1576 - accuracy: 0.9325\n","Epoch 57/100\n","62500/62500 [==============================] - 12s 184us/step - loss: 0.1586 - accuracy: 0.9312\n","Epoch 58/100\n","62500/62500 [==============================] - 12s 184us/step - loss: 0.1617 - accuracy: 0.9303\n","Epoch 59/100\n","62500/62500 [==============================] - 12s 185us/step - loss: 0.1501 - accuracy: 0.9355\n","Epoch 60/100\n","62500/62500 [==============================] - 12s 184us/step - loss: 0.1595 - accuracy: 0.9314\n","Epoch 61/100\n","62500/62500 [==============================] - 12s 184us/step - loss: 0.1501 - accuracy: 0.9363\n","Epoch 62/100\n","62500/62500 [==============================] - 11s 184us/step - loss: 0.1474 - accuracy: 0.9367\n","Epoch 63/100\n","62500/62500 [==============================] - 11s 184us/step - loss: 0.1432 - accuracy: 0.9388\n","Epoch 64/100\n","62500/62500 [==============================] - 12s 185us/step - loss: 0.1490 - accuracy: 0.9366\n","Epoch 65/100\n","62500/62500 [==============================] - 11s 184us/step - loss: 0.1485 - accuracy: 0.9366\n","Epoch 66/100\n","62500/62500 [==============================] - 12s 185us/step - loss: 0.1453 - accuracy: 0.9376\n","Epoch 67/100\n","62500/62500 [==============================] - 11s 184us/step - loss: 0.1376 - accuracy: 0.9416\n","Epoch 68/100\n","62500/62500 [==============================] - 11s 183us/step - loss: 0.1351 - accuracy: 0.9425\n","Epoch 69/100\n","62500/62500 [==============================] - 11s 183us/step - loss: 0.1476 - accuracy: 0.9373\n","Epoch 70/100\n","62500/62500 [==============================] - 12s 184us/step - loss: 0.1394 - accuracy: 0.9412\n","Epoch 71/100\n","62500/62500 [==============================] - 12s 188us/step - loss: 0.1386 - accuracy: 0.9412\n","Epoch 72/100\n","62500/62500 [==============================] - 11s 184us/step - loss: 0.1368 - accuracy: 0.9424\n","Epoch 73/100\n","62500/62500 [==============================] - 12s 185us/step - loss: 0.1318 - accuracy: 0.9448\n","Epoch 74/100\n","62500/62500 [==============================] - 11s 183us/step - loss: 0.1337 - accuracy: 0.9429\n","Epoch 75/100\n","62500/62500 [==============================] - 11s 183us/step - loss: 0.1323 - accuracy: 0.9442\n","Epoch 76/100\n","62500/62500 [==============================] - 11s 184us/step - loss: 0.1387 - accuracy: 0.9404\n","Epoch 77/100\n","62500/62500 [==============================] - 11s 182us/step - loss: 0.1317 - accuracy: 0.9451\n","Epoch 78/100\n","62500/62500 [==============================] - 11s 183us/step - loss: 0.1268 - accuracy: 0.9466\n","Epoch 79/100\n","62500/62500 [==============================] - 11s 183us/step - loss: 0.1239 - accuracy: 0.9478\n","Epoch 80/100\n","62500/62500 [==============================] - 11s 183us/step - loss: 0.1220 - accuracy: 0.9482\n","Epoch 81/100\n","62500/62500 [==============================] - 12s 185us/step - loss: 0.1314 - accuracy: 0.9457\n","Epoch 82/100\n","62500/62500 [==============================] - 11s 184us/step - loss: 0.1200 - accuracy: 0.9492\n","Epoch 83/100\n","62500/62500 [==============================] - 11s 184us/step - loss: 0.1276 - accuracy: 0.9474\n","Epoch 84/100\n","62500/62500 [==============================] - 11s 184us/step - loss: 0.1243 - accuracy: 0.9476\n","Epoch 85/100\n","62500/62500 [==============================] - 11s 183us/step - loss: 0.1228 - accuracy: 0.9477\n","Epoch 86/100\n","62500/62500 [==============================] - 11s 183us/step - loss: 0.1240 - accuracy: 0.9477\n","Epoch 87/100\n","62500/62500 [==============================] - 11s 183us/step - loss: 0.1147 - accuracy: 0.9520\n","Epoch 88/100\n","62500/62500 [==============================] - 11s 183us/step - loss: 0.1171 - accuracy: 0.9501\n","Epoch 89/100\n","62500/62500 [==============================] - 11s 183us/step - loss: 0.1223 - accuracy: 0.9485\n","Epoch 90/100\n","62500/62500 [==============================] - 11s 183us/step - loss: 0.1189 - accuracy: 0.9503\n","Epoch 91/100\n","62500/62500 [==============================] - 12s 184us/step - loss: 0.1161 - accuracy: 0.9514\n","Epoch 92/100\n","62500/62500 [==============================] - 11s 184us/step - loss: 0.1193 - accuracy: 0.9496\n","Epoch 93/100\n","62500/62500 [==============================] - 11s 183us/step - loss: 0.1089 - accuracy: 0.9545\n","Epoch 94/100\n","62500/62500 [==============================] - 11s 183us/step - loss: 0.1078 - accuracy: 0.9548\n","Epoch 95/100\n","62500/62500 [==============================] - 11s 182us/step - loss: 0.1150 - accuracy: 0.9521\n","Epoch 96/100\n","62500/62500 [==============================] - 11s 182us/step - loss: 0.1172 - accuracy: 0.9509\n","Epoch 97/100\n","62500/62500 [==============================] - 11s 183us/step - loss: 0.1171 - accuracy: 0.9510\n","Epoch 98/100\n","62500/62500 [==============================] - 12s 186us/step - loss: 0.1173 - accuracy: 0.9505\n","Epoch 99/100\n","62500/62500 [==============================] - 12s 184us/step - loss: 0.1064 - accuracy: 0.9551\n","Epoch 100/100\n","62500/62500 [==============================] - 11s 183us/step - loss: 0.1019 - accuracy: 0.9573\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"z48sHukBqqHh"},"source":["## Making Predictions with the Model\n","\n","`Decomposer.classify(X)` decomposes the images of `X` into windows and then calls `XceptionModel.classify(X)` to do the patchwise classification, but it **does not** recompose the images. This is true for all the patchwise classifiers we created, because having patchwise predictions can be useful in certain cases.\n","\n","If you want the model to return full masks, you need to wrap it into a `Recomposer` decorator, as below. The implementation of this decorator class can be found in `recomposer.py`."]},{"cell_type":"code","metadata":{"id":"vSP2KceOsOd7","colab_type":"code","colab":{}},"source":["from recomposer import *\n","model = Recomposer(model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M6IRaQ8E8TPB","colab_type":"text"},"source":["The function `nb_predict_masks` is an helper function provided in `util/notebooks.py`, while `masks_to_submission` is a function based on the implementation provided in the Kaggle competition.\n","\n","The following two cells can be skipped if you do not want to generate the `.csv` file."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5C5PHZKP9bKi","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1595173138690,"user_tz":-120,"elapsed":1175635,"user":{"displayName":"osnapitzkindle","photoUrl":"https://lh5.googleusercontent.com/-WviiFWOc9yU/AAAAAAAAAAI/AAAAAAAAABg/5UfVNmCmUPs/s64/photo.jpg","userId":"17296883532666308644"}},"outputId":"a93c21cc-5a2e-4f53-c580-f29253ec5686"},"source":["test_masks_dir = \"test/pred/xception/\"\n","test_dir = \"test/images/\"\n"," \n","nb_predict_masks(model, test_dir, test_masks_dir)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Predicting test cases... \n","Progress: done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"eQQ7wKtmGOdM","colab":{}},"source":["image_paths = [test_masks_dir + file for file in os.listdir(test_masks_dir)]\n","masks_to_submission(\"test/xception.csv\", image_paths)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jcmPnqFFs3vb","colab_type":"text"},"source":["This prediction achieved an F1 score of XXX in Kaggle's public test set."]},{"cell_type":"markdown","metadata":{"id":"5iiRoNEP7y4n","colab_type":"text"},"source":["# Visualizing predictions\n","\n","The function `view_image_array` is provided in `util/visualize.py`. It uses `matplotlib` to visualize the images and the corresponding predictions."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"MiKljqBGpCkq","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1y77HP4gaS1WV8lRwcfKOL53N9OP-8hd_"},"executionInfo":{"status":"ok","timestamp":1595173157058,"user_tz":-120,"elapsed":1193975,"user":{"displayName":"osnapitzkindle","photoUrl":"https://lh5.googleusercontent.com/-WviiFWOc9yU/AAAAAAAAAAI/AAAAAAAAABg/5UfVNmCmUPs/s64/photo.jpg","userId":"17296883532666308644"}},"outputId":"ffd5b5e0-b5e7-494e-ea56-65f2375d5c69"},"source":["Y_pred = model.classify(X_test[0:10])\n","\n","view_image_array(X_test[0:10], Y_pred)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}