{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googlenet import create_googlenet\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
    "from decomposer import *\n",
    "from util.config import *\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import Sequential\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.xception import Xception\n",
    "\n",
    "\n",
    "# let's say we want just 1 output\n",
    "def batch_generator(bootstrap):\n",
    "    while 1:\n",
    "        # create one batch\n",
    "        X_batch = np.empty((batch_size, window_size, window_size, 3))\n",
    "        Y_batch = np.empty(batch_size)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            Y_batch[i], X_batch[i] = next(bootstrap)\n",
    "\n",
    "        yield (X_batch, Y_batch)\n",
    "\n",
    "\n",
    "class cnn_trial(ModelBase):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    def initialize(self):\n",
    "        input_shape=(72,72,3)\n",
    "        xcept = Xception(weights=\"imagenet\",include_top = False, input_shape = input_shape, classes = 1)\n",
    "        print('create xcept model')\n",
    "        output = xcept.layers[-1].output\n",
    "        output = Flatten()(output)\n",
    "        xcept = Model(xcept.input, output)\n",
    "\n",
    "    \n",
    "        model = Sequential()\n",
    "        model.add(xcept)\n",
    "        model.add(Dense(64, activation='relu', input_dim=input_shape))\n",
    "        model.add(Dropout(rate = 0.3))\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(Dropout(rate = 0.3))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        print('created xcept model successfully')\n",
    "        self.model = model\n",
    "        self.model.summary()\n",
    "\n",
    "                                                 \n",
    "        for i, layer in enumerate(xcept.layers):\n",
    "            print(i, layer.name)\n",
    "\n",
    "        for layer in xcept.layers[:75]:\n",
    "            layer.trainable = False\n",
    "\n",
    "        for layer in xcept.layers[0:]:\n",
    "            layer.trainable = True\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "    def load(self, filename):\n",
    "        self.model.load_weights(filename)\n",
    "\n",
    "    def save(self, filename):\n",
    "        self.model.save_weights(filename)\n",
    "\n",
    "    def train_online(self, generator):\n",
    "        # this generator does the bootstrap of a single sample.\n",
    "        # batch_generator will create batches of these samples\n",
    "\n",
    "        # TODO choose an optimizer, and a loss function\n",
    "        adam = Adam(lr=0.001)  # Adam optimizer with default initial learning rate\n",
    "\n",
    "        self.model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        lr_callback = ReduceLROnPlateau(monitor='accuracy', factor=0.5, patience=5,\n",
    "                                        verbose=1, mode='auto', epsilon=0.0001, cooldown=0, min_lr=0)\n",
    "\n",
    "        # Stops the training process upon convergence\n",
    "        stop_callback = EarlyStopping(monitor='accuracy', min_delta=0.0001, patience=11, verbose=1, mode='auto')\n",
    "        callbacks = [\n",
    "            EarlyStopping(monitor='loss', patience=2, verbose=1, mode='auto'),\n",
    "            ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5,\n",
    "                                    verbose=1, mode='auto', epsilon=0.0001, cooldown=0, min_lr=0)\n",
    "            \n",
    "        ]\n",
    "\n",
    "        np.random.seed(3)  # fix randomness\n",
    "        self.model.fit_generator(batch_generator(generator),\n",
    "                                 steps_per_epoch=steps_per_epoch,\n",
    "                                 epochs=epochs,\n",
    "                                 verbose=1,\n",
    "                                 callbacks=[lr_callback, stop_callback])\n",
    "\n",
    "    def classify(self, X):\n",
    "        Z = self.model.predict(X)\n",
    "        Z = ((Z) > 0.5).astype(int)\n",
    "\n",
    "        return Z"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
